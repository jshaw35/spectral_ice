{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1b99799-cc4f-495a-b1cc-1ad418bf0ed0",
   "metadata": {},
   "source": [
    "# Methods Figures for Shaw and Kay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae684299-3197-4d13-b683-35037b5d5b96",
   "metadata": {},
   "source": [
    "__1. Debunk the use of synthetic ensembles for estimating internal variability from a single simulation.__\n",
    "\n",
    "Show that using a single simulation and calculating its noise statistics underestimates the variability of OLR in CESM1. Follow the synthetic methods of Sledd (2021). I expect to see differences in the range of long-term slopes, as well as in the 95% confidence interval in time space. Who knows though, maybe the synthetic ensemble will be OK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed24f8f-f610-4c81-9ad3-5abb7ab8a64c",
   "metadata": {},
   "source": [
    "__2. Show that observationally estimated internal variability is both highly uncertain and low-biased when estimated from 20-year records.__\n",
    "\n",
    "- Use the forced CESM1-LE members to generate a binormal distribution showing that there is a large possible range of internal variability at 20 years\n",
    "- Plot the internal variability from CERES OLR obs., I anticipate that they will fall within the CESM1-LE range, preventing us from invalidating the model\n",
    "- Plot a \"true\" internal variability from the CESM1 1800-yr control run, demonstrating that a short record also biases the internal variability low for both characteristics ($\\tau_{var}$ and $\\sigma_{var}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ddf019-d9ab-47e7-bc5f-d6704f3e627c",
   "metadata": {},
   "source": [
    "__*.__ __Show the importantance (or lack thereof) of changing internal climate variability on estimates of climate signal emergence.__\n",
    "\n",
    "_I need a simple framework for comparing these two results, but one isn't immediately obvious to me. Ultimately, I need an \"experiment\" where only one variable has been changed. Brainstorming below..._\n",
    "\n",
    "The unforced envelope of variability does not change, but the forced envelope of variability does. The SNR approach does not anticipate these terms being different, so it isn't suited to answer this question. __Better to use a simple approach after validating it against the SNR method.__ We're really asking, how do identical confidence intervals on the forced and unforced simulations differ as the record gets longer. Specifically, we ask this question for OLR over the central Arctic, because Barnhart (2016) has already evaluated it by gridcell.\n",
    "\n",
    "- Calculate emergence using the SNR approach and calculating the internal climate variability from the PIC simulation (time-constant variability). <-- If we use the forced response to estimate emergence here, were effectively ignoring the changing internal variability in the forced simulations. But if we want to see how the confidence interval is affected we'll have to use a different approach.\n",
    "\n",
    "- Calculate emergence by comparing confidence intervals using the unforced envelope centered at the forced slope (emergence ignoring changes in internal variability) and the forced envelope centered at the forced slope (emergence account for changes in internal variability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76c970-a25c-4443-9fae-378eade29bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-cheycomp]",
   "language": "python",
   "name": "conda-env-miniconda3-cheycomp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
